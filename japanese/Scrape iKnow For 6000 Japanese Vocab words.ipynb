{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This code creates a csv file with 6000 most common japanese words with sentences. Thanks iKnow for making this data available. This site was hard to scrape so I had to use selenium so that firefox would run the Javascript.\n",
    "\n",
    "## To use this, you need:\n",
    "- selenium! Google how to install it on your system\n",
    "- python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "opts.headless = True\n",
    "browser = Firefox(options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The word lists are divided up into pages with 100 words each, so this code scrapes the list of urls from the table of contents page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://iknow.jp/content/japanese')\n",
    "url_list = []\n",
    "url_set = set()\n",
    "for cont in browser.find_elements_by_class_name(\"series_container\"):\n",
    "    for course_container in browser.find_elements_by_class_name(\"course_container\"):\n",
    "        ul = course_container.find_element_by_tag_name(\"ul\")\n",
    "        for li in ul.find_elements_by_tag_name(\"li\"):\n",
    "            a = li.find_element_by_tag_name(\"a\")\n",
    "            title = a.get_property(\"title\")\n",
    "            if re.match(r\"Japanese Core \\d000.+\", title):\n",
    "                url = a.get_attribute(\"href\")\n",
    "                if url not in url_set:\n",
    "                    url_list.append(url)\n",
    "                    url_set.add(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should be 60 unique urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(url_list) == len(set(url_list))\n",
    "len(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100522192b1e4076ab180ffe1672ecb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "for url in tqdm(url_list):\n",
    "    \n",
    "    browser.get(url)\n",
    "    \n",
    "    \n",
    "    content = browser.find_elements_by_class_name(\"course-content\")\n",
    "    ul = content[0].find_element_by_tag_name(\"ul\")\n",
    "    for li in ul.find_elements_by_tag_name(\"li\"):\n",
    "    \n",
    "        # Find the actual word\n",
    "        item_details = li.find_element_by_class_name(\"item-details\")\n",
    "        text = item_details.find_element_by_class_name(\"text\")\n",
    "\n",
    "        word_text = text.text.strip()\n",
    "        match = re.match(r\"([^\\W\\d_]+) \\[([^\\W\\d_]+)\\]\", word_text)\n",
    "        if match:\n",
    "            word = match.group(1)\n",
    "            pron = match.group(2)\n",
    "        else:\n",
    "            word = word_text\n",
    "            pron = None\n",
    "        translation = item_details.find_element_by_class_name(\"response\").text\n",
    "\n",
    "        # Get sentences\n",
    "        item_sents = li.find_element_by_class_name(\"item-sentences\")\n",
    "        sents = item_sents.find_elements_by_class_name(\"text\")\n",
    "        tl = item_sents.find_elements_by_class_name(\"transliteration\")\n",
    "        tn = item_sents.find_elements_by_class_name(\"translation\")\n",
    "\n",
    "        def get_sent_dict(i):\n",
    "            return dict(sentence=sents[i].text,transliteration=tl[i].text,\n",
    "                       translation=tn[i].text)\n",
    "\n",
    "        sent1 = get_sent_dict(0)\n",
    "        try:\n",
    "            sent2=get_sent_dict(1)\n",
    "        except IndexError:\n",
    "            sent2 = None\n",
    "        entry = dict(word=word, pron=pron, translation=translation, \n",
    "                     sent1=sent1, sent2=sent2)\n",
    "        word_list.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should be 6000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '行く',\n",
       "  'pron': 'いく',\n",
       "  'translation': 'go',\n",
       "  'sent1': {'sentence': '日曜日は図書館に行きます。',\n",
       "   'transliteration': 'にちようび は としょかん に いきます。',\n",
       "   'translation': 'I go to the library on Sundays.'},\n",
       "  'sent2': {'sentence': '私は夏休みにプールに行った。',\n",
       "   'transliteration': 'わたし は なつやすみ に プール に いった。',\n",
       "   'translation': 'I went to the pool during summer vacation.'}},\n",
       " {'word': '見る',\n",
       "  'pron': 'みる',\n",
       "  'translation': 'see, look at',\n",
       "  'sent1': {'sentence': '私は絵を見るのが好きです。',\n",
       "   'transliteration': 'わたし は え を みる の が すき です。',\n",
       "   'translation': 'I like looking at pictures.'},\n",
       "  'sent2': {'sentence': '仕事のあと、映画を見た。',\n",
       "   'transliteration': 'しごと の あと、 えいが を みた。',\n",
       "   'translation': 'I saw a movie after work.'}},\n",
       " {'word': '多い',\n",
       "  'pron': 'おおい',\n",
       "  'translation': 'a lot of, many',\n",
       "  'sent1': {'sentence': '京都にはお寺が多い。',\n",
       "   'transliteration': 'きょうと に は おてら が おおい。',\n",
       "   'translation': 'There are a lot of temples in Kyoto.'},\n",
       "  'sent2': {'sentence': 'この道は車が多い。',\n",
       "   'transliteration': 'この みち は くるま が おおい。',\n",
       "   'translation': 'There are many cars on this road.'}},\n",
       " {'word': '家',\n",
       "  'pron': 'うち',\n",
       "  'translation': 'home, household',\n",
       "  'sent1': {'sentence': '家に遊びにきてください。',\n",
       "   'transliteration': 'うち に あそび に きて ください。',\n",
       "   'translation': 'Please come over to my home.'},\n",
       "  'sent2': {'sentence': '夏休みにお祖母ちゃんの家へ行きました。',\n",
       "   'transliteration': 'なつやすみ に おばあちゃん の うち へ いきました。',\n",
       "   'translation': \"I went to my grandma's house during summer vacation.\"}},\n",
       " {'word': 'これ',\n",
       "  'pron': None,\n",
       "  'translation': 'this, this one',\n",
       "  'sent1': {'sentence': 'これをください。',\n",
       "   'transliteration': 'これ を ください。',\n",
       "   'translation': \"I'll have this please.\"},\n",
       "  'sent2': {'sentence': 'これはあなたの鞄ですか。',\n",
       "   'transliteration': 'これ は あなた の かばん です か。',\n",
       "   'translation': 'Is this your bag?'}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('japanese6000.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='\\t')\n",
    "    writer.writerow(\"word kana english sent1 sent1_kana sent1_english sent2 sent2_kana sent2_english\".split())\n",
    "    for d in word_list:\n",
    "        word = d[\"word\"]\n",
    "        kana = d[\"pron\"]\n",
    "        if kana is None:\n",
    "            kana = word\n",
    "        english = d[\"translation\"]\n",
    "        def get_sentence_list(sent_dict):\n",
    "            if sent_dict is None:\n",
    "                return [\"\"]*3\n",
    "            else:\n",
    "                return [sent_dict[\"sentence\"], \n",
    "                        sent_dict[\"transliteration\"],\n",
    "                       sent_dict[\"translation\"]]\n",
    "        row = [word, kana, english] + get_sentence_list(d[\"sent1\"]) + get_sentence_list(d[\"sent2\"])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('japanese6000.pkl', 'wb') as f:\n",
    "    pickle.dump(word_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
