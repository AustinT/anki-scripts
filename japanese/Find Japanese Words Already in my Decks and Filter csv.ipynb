{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This notebook interfaces with my Anki deck to extract which vocab words were already in my Japanese decks.\n",
    "\n",
    "Fot this to run, the file `japanese6000.csv` should already be present in the directory.\n",
    "\n",
    "\n",
    "This website was extremely useful: \n",
    "https://www.juliensobczak.com/write/2016/12/26/anki-scripting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = \"/home/austin/.local/share/Anki2/User 1/collection.anki2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_file)\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find which note types are in my Japanese deck\n",
    "My Japanese Deck id was determined to be 1452955218348 (via manual looking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jap_note_types = set()\n",
    "c.execute('SELECT nid FROM cards WHERE did is \"1452955218348\"')\n",
    "all_note_ids = c.fetchall()\n",
    "for note_id in all_note_ids:\n",
    "    c.execute('SELECT mid FROM notes WHERE id = {}'.format(note_id[0]))\n",
    "    jap_note_types.add(c.fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1722847518,\n",
       " 1356965744391,\n",
       " 1356968358402,\n",
       " 1452394503690,\n",
       " 1453856798407,\n",
       " 1470748883844,\n",
       " 1471914315711}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jap_note_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356968358402 Katakana with stroke diagrams and audio\n",
      "1470748883844 Jap_Word_card\n",
      "1356965744391 Hiragana with stroke diagrams and audio\n",
      "1453856798407 Grammar3_morphology_cloze\n",
      "1452394503690 Grammar1_whole_sentence_translate\n",
      "1722847518 Japanese\n",
      "1471914315711 Kanji_Card\n"
     ]
    }
   ],
   "source": [
    "# Create list of all note types\n",
    "import json\n",
    "c.execute(\"SELECT models FROM col\")\n",
    "all_note_types = c.fetchone()[0]\n",
    "all_note_types = json.loads(all_note_types)\n",
    "\n",
    "# Print off note types in the Japanese decks\n",
    "for jnt in jap_note_types:\n",
    "    print(jnt, all_note_types[str(jnt)]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Japanese Cards with note (=model) type 1722847518\n",
    "This is my existing \"2000 Japanese words vocab deck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = []\n",
    "c.execute('SELECT flds FROM notes WHERE mid is 1722847518')\n",
    "all_fields = c.fetchall()\n",
    "for fields_str in all_fields:\n",
    "    \n",
    "    fields = fields_str[0].split(\"\\x1f\")\n",
    "    if any(s in fields[0] for s in [\"Japanese Core\", \"Core Step\"]):\n",
    "        vocab_list.append(fields[1])\n",
    "    else:\n",
    "        raise RuntimeError(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exactly 2000 words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"Existing words.pkl\", \"wb\") as f:\n",
    "    pkl.dump(vocab_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the 6000 words csv\n",
    "Put only the new words into a file for importing into my Anki deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "already_have_vocab = set(vocab_list)\n",
    "rows_to_keep = []\n",
    "with open(\"japanese6000.csv\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    next(reader) # Get rid of the header\n",
    "    \n",
    "    for row in reader:\n",
    "        if row[0] not in already_have_vocab:\n",
    "            rows_to_keep.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4066"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the new csv file\n",
    "with open(\"japanese6000_new.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    \n",
    "    for row in rows_to_keep:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
